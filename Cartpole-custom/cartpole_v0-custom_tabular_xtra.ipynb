{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 161\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "XTRA_FEAT   = 3 #masscart, masspole, length\n",
    "N_ACTIONS   = env.action_space.n\n",
    "N_STATES    = env.observation_space.shape[0]  +  XTRA_FEAT \n",
    "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     # to confirm the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndim_grid(start,stop, granularity):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.linspace(start[i],stop[i],granularity) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(value, borders):\n",
    "    c_pos_val, c_vel_val, p_ang_val, p_vel_val, mcart_val, mpole_val, length_val   = value\n",
    "    c_pos_s  , c_vel_s  ,p_ang_s   , p_vel_s  , mcart_s  , mpole_s  , length_s     = borders\n",
    "    \n",
    "    c_pos_indx  = np.where(c_pos_s  >= c_pos_val )[0][0].astype(int)\n",
    "    c_vel_indx  = np.where(c_vel_s  >= c_vel_val )[0][0].astype(int)\n",
    "    p_ang_indx  = np.where(p_ang_s  >= p_ang_val )[0][0].astype(int)\n",
    "    p_vel_indx  = np.where(p_vel_s  >= p_vel_val )[0][0].astype(int)\n",
    "    mcart_indx  = np.where(mcart_s  >= mcart_val )[0][0].astype(int)\n",
    "    mpole_indx  = np.where(mpole_s  >= mpole_val )[0][0].astype(int)\n",
    "    length_indx = np.where(length_s >= length_val)[0][0].astype(int)\n",
    "    \n",
    "    \n",
    "    return [c_pos_indx, c_vel_indx, p_ang_indx, p_vel_indx, mcart_indx, mpole_indx, length_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NODES:  1\n",
      "Number of EPISODES per NODE 10\n"
     ]
    }
   ],
   "source": [
    "T_LR           = 1e-1\n",
    "T_GAMMA        = 0.95\n",
    "T_EPSILON      = 0.98\n",
    "\n",
    "NO_OF_NODES    = 1\n",
    "NO_OF_EPISODES = 50\n",
    "TIMESTEP_LIMIT = 200\n",
    "\n",
    "print(\"Number of NODES: \", NO_OF_NODES)\n",
    "print(\"Number of EPISODES per NODE\", NO_OF_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "HIDDEN_LAYER        = 50\n",
    "BATCH_SIZE          = 32\n",
    "NN_LR               = 1e-3  # learning rate\n",
    "NN_GAMMA            = 0.9   # reward discount\n",
    "TARGET_REPLACE_ITER = 100   # target update frequency\n",
    "TERMINAL_BIAS       = 0.5   # no. of terminal memories in batch\n",
    "MIN_MEMORY_CAP      = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.adv = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.adv.weight) \n",
    "    \n",
    "        self.val = nn.Linear(HIDDEN_LAYER, 1)\n",
    "        nn.init.xavier_uniform_(self.val.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        \n",
    "        return val + adv - adv.mean()\n",
    "    \n",
    "class D3QN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "\n",
    "        self.learn_step_counter  = 0 # for target updating\n",
    "        \n",
    "        self.good_memory_counter = 0 # for storing non-terminal memories\n",
    "        self.good_memory         = np.zeros((MIN_MEMORY_CAP ,N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.bad_memory_counter  = 0 # for storing terminal memories\n",
    "        self.bad_memory          = np.zeros((MIN_MEMORY_CAP , N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.optimizer           = torch.optim.Adam(self.eval_net.parameters(), lr=NN_LR)\n",
    "        self.loss_func           = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.data.numpy()\n",
    "        return actions_value\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        good_sample_index_limit = min(MIN_MEMORY_CAP, self.good_memory_counter)\n",
    "        bad_sample_index_limit = min(MIN_MEMORY_CAP, self.bad_memory_counter)\n",
    "\n",
    "        good_sample_index = np.random.choice(int(good_sample_index_limit), int(BATCH_SIZE-int(BATCH_SIZE*TERMINAL_BIAS)))\n",
    "        bad_sample_index  = np.random.choice(int(bad_sample_index_limit),  int(BATCH_SIZE*TERMINAL_BIAS))\n",
    "\n",
    "        b_good_memory = self.good_memory[good_sample_index, :]\n",
    "        b_bad_memory  = self.bad_memory[bad_sample_index, :]\n",
    "        b_memory      = np.vstack((b_good_memory,b_bad_memory))\n",
    "        \n",
    "        b_s  = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a  = torch.LongTensor( b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r  = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval   = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        a_eval   = self.eval_net(b_s).max(1)[1].view(BATCH_SIZE, 1) #best action according to eval_net\n",
    "        q_next   = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + NN_GAMMA * q_next.gather(1, a_eval)   # shape (batch, 1)\n",
    "        loss     = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "node_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET SEED\n",
    "###############################################\n",
    "my_seed = seed + node_id + iteration\n",
    "random.seed(my_seed)\n",
    "torch.manual_seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "my_env = env\n",
    "my_env.seed(my_seed);\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET STATE VALUE BORDERS\n",
    "###############################################\n",
    "C_POS_MAX =  5\n",
    "C_POS_MIN = -5\n",
    "\n",
    "C_VEL_MAX =  5\n",
    "C_VEL_MIN = -5\n",
    "\n",
    "P_ANG_MAX =  1\n",
    "P_ANG_MIN = -1\n",
    "\n",
    "P_VEL_MAX =  5\n",
    "P_VEL_MIN = -5\n",
    "\n",
    "M_CART_MAX = 1.4\n",
    "M_CART_MIN = 0.6\n",
    "\n",
    "M_POLE_MAX = 0.14\n",
    "M_POLE_MIN = 0.06\n",
    "\n",
    "LENGTH_MAX = 0.7\n",
    "LENGTH_MIN = 0.3\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET GRANULARITY\n",
    "GRANULARITY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATE TABLE BORDERS\n",
    "###############################################\n",
    "c_pos_s  = np.linspace(C_POS_MIN,  C_POS_MAX,  GRANULARITY)\n",
    "c_vel_s  = np.linspace(C_VEL_MIN,  C_VEL_MAX,  GRANULARITY)\n",
    "p_ang_s  = np.linspace(P_ANG_MIN,  P_ANG_MAX,  GRANULARITY)\n",
    "p_vel_s  = np.linspace(P_VEL_MIN,  P_VEL_MAX,  GRANULARITY)\n",
    "mcart_s  = np.linspace(M_CART_MIN, M_CART_MAX, GRANULARITY)\n",
    "mpole_s  = np.linspace(M_POLE_MIN, M_POLE_MAX, GRANULARITY)\n",
    "length_s = np.linspace(LENGTH_MIN, LENGTH_MAX, GRANULARITY)\n",
    "\n",
    "borders = [c_pos_s, c_vel_s, p_ang_s, p_vel_s, mcart_s, mpole_s, length_s]\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATE COMBINATIONS\n",
    "###############################################\n",
    "\n",
    "state_combinations = ndim_grid([C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN, M_CART_MIN, M_POLE_MIN, LENGTH_MIN],\n",
    "                               [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX, M_CART_MAX, M_POLE_MAX, LENGTH_MAX],\n",
    "                                GRANULARITY)\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dqn = D3QN()\n",
    "MODEL_FILENAME = './models/cartpole_v0-custom_xtra_21_40_48'\n",
    "my_dqn.eval_net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "my_dqn.eval_net.eval()\n",
    "my_Q_TABLE = my_dqn.get_qvals(state_combinations).reshape(GRANULARITY, GRANULARITY, GRANULARITY, GRANULARITY,\n",
    "                                                          GRANULARITY, GRANULARITY, GRANULARITY, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_rec                = np.zeros(NO_OF_EPISODES)\n",
    "# level_up_flag           = False\n",
    "# PERFECT_RUN_COUNTER     = 10\n",
    "# PERFECT_RUNS_HIGH_SCORE = 10\n",
    "# level_up_metric         = 195\n",
    "exp_rec      = np.empty(N_STATES * 2 + 2)\n",
    "my_EPSILON   = T_EPSILON\n",
    "my_LR        = T_LR\n",
    "\n",
    "while True:\n",
    "    i_episode = 0\n",
    "\n",
    "    my_env.masscart = 1.0 * np.random.uniform(0.6,1.4)\n",
    "    my_env.masspole = 0.1 * np.random.uniform(0.6,1.4)\n",
    "    my_env.length   = 0.5 * np.random.uniform(0.6,1.4)\n",
    "\n",
    "    xtra = [my_env.masscart, my_env.masspole, my_env.length]\n",
    "\n",
    "    while i_episode < NO_OF_EPISODES:\n",
    "        ep_exp_rec = np.empty(N_STATES * 2 + 2)\n",
    "        time_steps = 0\n",
    "\n",
    "        s = my_env.reset()\n",
    "        s = np.append(s, xtra)\n",
    "\n",
    "        while True:\n",
    "            this_state = tuple(discretize(s, borders))\n",
    "\n",
    "            time_steps += 1\n",
    "            if np.random.uniform() > my_EPSILON:   # greedy\n",
    "                a = np.random.randint(0, N_ACTIONS)\n",
    "            else:\n",
    "                a = my_Q_TABLE[this_state][:].argmax()\n",
    "\n",
    "             # take action\n",
    "            s_, r, done, info = my_env.step(a)\n",
    "            s_ = np.append(s_, xtra)\n",
    "\n",
    "            if done:\n",
    "                r = -1\n",
    "                if time_steps >= TIMESTEP_LIMIT:\n",
    "                    r = 1\n",
    "\n",
    "            experience = np.hstack((s,a,r,s_))\n",
    "            exp_rec = np.vstack((exp_rec, experience))\n",
    "\n",
    "            #discretize next_state\n",
    "            next_state = tuple(discretize(s_, borders))\n",
    "\n",
    "            # learn\n",
    "\n",
    "            my_Q_TABLE[this_state][a] = my_Q_TABLE[this_state][a] + my_LR * (r + T_GAMMA * my_Q_TABLE[next_state].max() - \n",
    "                                                                     my_Q_TABLE[this_state][a])\n",
    "            if done or time_steps >= TIMESTEP_LIMIT:\n",
    "                time_rec[i_episode] = time_steps\n",
    "                break\n",
    "            s = s_\n",
    "\n",
    "        i_episode += 1\n",
    "    if i_episode >= NO_OF_EPISODES:\n",
    "        i_episode = 0\n",
    "        break\n",
    "\n",
    "exp_rec = np.delete(exp_rec, 0, 0)\n",
    "#     message = \"NODE#\"+str(node_id) +\" MAIN Q:\"+ str(new_Q_TABLE.mean()) +\"\\t\" + \"NODE Q:\" + str(my_Q_TABLE.mean())\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_time_rec = time_rec\n",
    "##################################################################\n",
    "\n",
    "# PLOT EXPERIENCES\n",
    "##################################################################\n",
    "node_avg_time = node_time_rec.mean()\n",
    "node_std_time = node_time_rec.std()\n",
    "node_max_time = node_time_rec.max()\n",
    "node_min_time = node_time_rec.min()\n",
    "\n",
    "fig = plt.figure(figsize = (15,3))\n",
    "ax2 = fig.add_subplot(1, 1, 1)\n",
    "ax2.set_title(\"Q-table Performance\")\n",
    "ax2.bar(range(NO_OF_NODES) , node_max_time, alpha = 0.1, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_avg_time, alpha = 0.5, color = 'g', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_min_time, alpha = 0.4, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "\n",
    "ax2.plot(np.ones_like(node_avg_time)*200, 'g--')\n",
    "ax2.set_ylabel('Mean Node Lifetime',color = 'g')\n",
    "ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "fig.tight_layout()\n",
    "ax2.grid()\n",
    "plt.show()\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
