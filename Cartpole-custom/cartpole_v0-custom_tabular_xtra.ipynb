{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 161\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "XTRA_FEAT   = 3 #masscart, masspole, length\n",
    "N_ACTIONS   = env.action_space.n\n",
    "N_STATES    = env.observation_space.shape[0]  +  XTRA_FEAT \n",
    "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     # to confirm the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndim_grid(start,stop, granularity):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.linspace(start[i],stop[i],granularity[i]) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(value, borders):\n",
    "    c_pos_val, c_vel_val, p_ang_val, p_vel_val, mcart_val, mpole_val, length_val   = value\n",
    "    c_pos_s  , c_vel_s  ,p_ang_s   , p_vel_s  , mcart_s  , mpole_s  , length_s     = borders\n",
    "    \n",
    "    c_pos_indx  = np.where(c_pos_s  >= c_pos_val )[0][0].astype(int)\n",
    "    c_vel_indx  = np.where(c_vel_s  >= c_vel_val )[0][0].astype(int)\n",
    "    p_ang_indx  = np.where(p_ang_s  >= p_ang_val )[0][0].astype(int)\n",
    "    p_vel_indx  = np.where(p_vel_s  >= p_vel_val )[0][0].astype(int)\n",
    "    mcart_indx  = np.where(mcart_s  >= mcart_val )[0][0].astype(int)\n",
    "    mpole_indx  = np.where(mpole_s  >= mpole_val )[0][0].astype(int)\n",
    "    length_indx = np.where(length_s >= length_val)[0][0].astype(int)\n",
    "    \n",
    "    \n",
    "    return [c_pos_indx, c_vel_indx, p_ang_indx, p_vel_indx, mcart_indx, mpole_indx, length_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NODES:  1\n",
      "Number of EPISODES per NODE 50\n"
     ]
    }
   ],
   "source": [
    "T_LR           = 1e-1\n",
    "T_GAMMA        = 0.95\n",
    "T_EPSILON      = 0.98\n",
    "\n",
    "NO_OF_NODES    = 1\n",
    "NO_OF_EPISODES = 50\n",
    "TIMESTEP_LIMIT = 200\n",
    "\n",
    "print(\"Number of NODES: \", NO_OF_NODES)\n",
    "print(\"Number of EPISODES per NODE\", NO_OF_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "HIDDEN_LAYER        = 50\n",
    "BATCH_SIZE          = 32\n",
    "NN_LR               = 1e-3  # learning rate\n",
    "NN_GAMMA            = 0.9   # reward discount\n",
    "TARGET_REPLACE_ITER = 100   # target update frequency\n",
    "TERMINAL_BIAS       = 0.5   # no. of terminal memories in batch\n",
    "MIN_MEMORY_CAP      = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(N_STATES, HIDDEN_LAYER)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)\n",
    "\n",
    "        self.adv = nn.Linear(HIDDEN_LAYER, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.adv.weight) \n",
    "    \n",
    "        self.val = nn.Linear(HIDDEN_LAYER, 1)\n",
    "        nn.init.xavier_uniform_(self.val.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        adv = self.adv(x)\n",
    "        val = self.val(x)\n",
    "        \n",
    "        return val + adv - adv.mean()\n",
    "    \n",
    "class D3QN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "\n",
    "        self.learn_step_counter  = 0 # for target updating\n",
    "        \n",
    "        self.good_memory_counter = 0 # for storing non-terminal memories\n",
    "        self.good_memory         = np.zeros((MIN_MEMORY_CAP ,N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.bad_memory_counter  = 0 # for storing terminal memories\n",
    "        self.bad_memory          = np.zeros((MIN_MEMORY_CAP , N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.optimizer           = torch.optim.Adam(self.eval_net.parameters(), lr=NN_LR)\n",
    "        self.loss_func           = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.data.numpy()\n",
    "        return actions_value\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        good_sample_index_limit = min(MIN_MEMORY_CAP, self.good_memory_counter)\n",
    "        bad_sample_index_limit = min(MIN_MEMORY_CAP, self.bad_memory_counter)\n",
    "\n",
    "        good_sample_index = np.random.choice(int(good_sample_index_limit), int(BATCH_SIZE-int(BATCH_SIZE*TERMINAL_BIAS)))\n",
    "        bad_sample_index  = np.random.choice(int(bad_sample_index_limit),  int(BATCH_SIZE*TERMINAL_BIAS))\n",
    "\n",
    "        b_good_memory = self.good_memory[good_sample_index, :]\n",
    "        b_bad_memory  = self.bad_memory[bad_sample_index, :]\n",
    "        b_memory      = np.vstack((b_good_memory,b_bad_memory))\n",
    "        \n",
    "        b_s  = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a  = torch.LongTensor( b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r  = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval   = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        a_eval   = self.eval_net(b_s).max(1)[1].view(BATCH_SIZE, 1) #best action according to eval_net\n",
    "        q_next   = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + NN_GAMMA * q_next.gather(1, a_eval)   # shape (batch, 1)\n",
    "        loss     = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 0\n",
    "node_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET SEED\n",
    "###############################################\n",
    "my_seed = seed + node_id + iteration\n",
    "random.seed(my_seed)\n",
    "torch.manual_seed(my_seed)\n",
    "np.random.seed(my_seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "my_env = env\n",
    "my_env.seed(my_seed);\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET STATE VALUE BORDERS\n",
    "###############################################\n",
    "C_POS_MAX =  5\n",
    "C_POS_MIN = -5\n",
    "\n",
    "C_VEL_MAX =  5\n",
    "C_VEL_MIN = -5\n",
    "\n",
    "P_ANG_MAX =  1\n",
    "P_ANG_MIN = -1\n",
    "\n",
    "P_VEL_MAX =  5\n",
    "P_VEL_MIN = -5\n",
    "\n",
    "M_CART_MAX = 1.4\n",
    "M_CART_MIN = 0.6\n",
    "\n",
    "M_POLE_MAX = 0.14\n",
    "M_POLE_MIN = 0.06\n",
    "\n",
    "LENGTH_MAX = 0.7\n",
    "LENGTH_MIN = 0.3\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET GRANULARITY\n",
    "LO_GRAIN = 5\n",
    "HI_GRAIN = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATE TABLE BORDERS\n",
    "###############################################\n",
    "c_pos_s  = np.linspace(C_POS_MIN,  C_POS_MAX,  HI_GRAIN)\n",
    "c_vel_s  = np.linspace(C_VEL_MIN,  C_VEL_MAX,  HI_GRAIN)\n",
    "p_ang_s  = np.linspace(P_ANG_MIN,  P_ANG_MAX,  HI_GRAIN)\n",
    "p_vel_s  = np.linspace(P_VEL_MIN,  P_VEL_MAX,  HI_GRAIN)\n",
    "mcart_s  = np.linspace(M_CART_MIN, M_CART_MAX, LO_GRAIN)\n",
    "mpole_s  = np.linspace(M_POLE_MIN, M_POLE_MAX, LO_GRAIN)\n",
    "length_s = np.linspace(LENGTH_MIN, LENGTH_MAX, LO_GRAIN)\n",
    "\n",
    "borders = [c_pos_s, c_vel_s, p_ang_s, p_vel_s, mcart_s, mpole_s, length_s]\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE STATE COMBINATIONS\n",
    "###############################################\n",
    "\n",
    "state_combinations = ndim_grid([C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN, M_CART_MIN, M_POLE_MIN, LENGTH_MIN ],\n",
    "                               [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX, M_CART_MAX, M_POLE_MAX, LENGTH_MAX ],\n",
    "                               [HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , LO_GRAIN  , LO_GRAIN  , LO_GRAIN])\n",
    "###############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dqn = D3QN()\n",
    "MODEL_FILENAME = './models/cartpole_v0-custom_xtra_21_40_48'\n",
    "my_dqn.eval_net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "my_dqn.eval_net.eval()\n",
    "my_Q_TABLE = my_dqn.get_qvals(state_combinations).reshape(HI_GRAIN , HI_GRAIN , HI_GRAIN , HI_GRAIN , \n",
    "                                                          LO_GRAIN , LO_GRAIN , LO_GRAIN , -1).astype(np.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_rec                = np.zeros(NO_OF_EPISODES)\n",
    "# level_up_flag           = False\n",
    "# PERFECT_RUN_COUNTER     = 10\n",
    "# PERFECT_RUNS_HIGH_SCORE = 10\n",
    "# level_up_metric         = 195\n",
    "exp_rec      = np.empty(N_STATES * 2 + 2)\n",
    "my_EPSILON   = T_EPSILON\n",
    "my_LR        = T_LR\n",
    "\n",
    "while True:\n",
    "    i_episode = 0\n",
    "\n",
    "    my_env.masscart = 1.0 * np.random.uniform(0.6,1.4)\n",
    "    my_env.masspole = 0.1 * np.random.uniform(0.6,1.4)\n",
    "    my_env.length   = 0.5 * np.random.uniform(0.6,1.4)\n",
    "\n",
    "    xtra = [my_env.masscart, my_env.masspole, my_env.length]\n",
    "\n",
    "    while i_episode < NO_OF_EPISODES:\n",
    "        ep_exp_rec = np.empty(N_STATES * 2 + 2)\n",
    "        time_steps = 0\n",
    "\n",
    "        s = my_env.reset()\n",
    "        s = np.append(s, xtra)\n",
    "\n",
    "        while True:\n",
    "            this_state = tuple(discretize(s, borders))\n",
    "\n",
    "            time_steps += 1\n",
    "            if np.random.uniform() > my_EPSILON:   # greedy\n",
    "                a = np.random.randint(0, N_ACTIONS)\n",
    "            else:\n",
    "                a = my_Q_TABLE[this_state][:].argmax()\n",
    "\n",
    "             # take action\n",
    "            s_, r, done, info = my_env.step(a)\n",
    "            s_ = np.append(s_, xtra)\n",
    "\n",
    "            if done:\n",
    "                r = -1\n",
    "                if time_steps >= TIMESTEP_LIMIT:\n",
    "                    r = 1\n",
    "\n",
    "            experience = np.hstack((s,a,r,s_))\n",
    "            exp_rec = np.vstack((exp_rec, experience))\n",
    "\n",
    "            #discretize next_state\n",
    "            next_state = tuple(discretize(s_, borders))\n",
    "\n",
    "            # learn\n",
    "\n",
    "            my_Q_TABLE[this_state][a] = my_Q_TABLE[this_state][a] + my_LR * (r + T_GAMMA * my_Q_TABLE[next_state].max() - \n",
    "                                                                     my_Q_TABLE[this_state][a])\n",
    "            if done or time_steps >= TIMESTEP_LIMIT:\n",
    "                time_rec[i_episode] = time_steps\n",
    "                break\n",
    "            s = s_\n",
    "\n",
    "        i_episode += 1\n",
    "    if i_episode >= NO_OF_EPISODES:\n",
    "        i_episode = 0\n",
    "        break\n",
    "\n",
    "exp_rec = np.delete(exp_rec, 0, 0)\n",
    "#     message = \"NODE#\"+str(node_id) +\" MAIN Q:\"+ str(new_Q_TABLE.mean()) +\"\\t\" + \"NODE Q:\" + str(my_Q_TABLE.mean())\n",
    "#     print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "node_time_rec = time_rec\n",
    "##################################################################\n",
    "\n",
    "# PLOT EXPERIENCES\n",
    "##################################################################\n",
    "node_avg_time = node_time_rec.mean()\n",
    "node_std_time = node_time_rec.std()\n",
    "node_max_time = node_time_rec.max()\n",
    "node_min_time = node_time_rec.min()\n",
    "\n",
    "fig = plt.figure(figsize = (15,3))\n",
    "ax2 = fig.add_subplot(1, 1, 1)\n",
    "ax2.set_title(\"Q-table Performance\")\n",
    "ax2.bar(range(NO_OF_NODES) , node_max_time, alpha = 0.1, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_avg_time, alpha = 0.5, color = 'g', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_min_time, alpha = 0.4, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "\n",
    "ax2.plot(np.ones_like(node_avg_time)*200, 'g--')\n",
    "ax2.set_ylabel('Mean Node Lifetime',color = 'g')\n",
    "ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "fig.tight_layout()\n",
    "ax2.grid()\n",
    "plt.show()\n",
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
