{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "import random\n",
    "import string\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 161\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "env = gym.make('CartPole-v0')\n",
    "N_ACTIONS   = env.action_space.n\n",
    "N_STATES    = env.observation_space.shape[0]\n",
    "ENV_A_SHAPE = 0 if isinstance(env.action_space.sample(), int) else env.action_space.sample().shape     # to confirm the shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID:  STI6WR1Z_20_03_36\n",
      "NN-MODEL FILENAME:  STI6WR1Z_20_03_36_NN.pt\n"
     ]
    }
   ],
   "source": [
    "RNDM_STRING = ''.join(random.choices(string.ascii_uppercase + string.digits, k=8)) + datetime.now().strftime(\"_%H_%M_%S\")\n",
    "print(\"ID: \",RNDM_STRING)\n",
    "MODEL_FILENAME = RNDM_STRING + \"_NN\" + \".pt\"\n",
    "print(\"NN-MODEL FILENAME: \", MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ndim_grid(start,stop, granularity):\n",
    "    # Set number of dimensions\n",
    "    ndims = len(start)\n",
    "\n",
    "    # List of ranges across all dimensions\n",
    "    L = [np.linspace(start[i],stop[i],granularity) for i in range(ndims)]\n",
    "\n",
    "    # Finally use meshgrid to form all combinations corresponding to all \n",
    "    # dimensions and stack them as M x ndims array\n",
    "    return np.hstack((np.meshgrid(*L))).swapaxes(0,1).reshape(ndims,-1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(value, borders):\n",
    "    c_pos_val, c_vel_val, p_ang_val, p_vel_val  = value\n",
    "    c_pos_s,   c_vel_s,   p_ang_s,   p_vel_s    = borders\n",
    "    c_pos_indx = np.where(c_pos_s >= c_pos_val)[0][0].astype(int)\n",
    "    c_vel_indx = np.where(c_vel_s >= c_vel_val)[0][0].astype(int)\n",
    "    p_ang_indx = np.where(p_ang_s >= p_ang_val)[0][0].astype(int)\n",
    "    p_vel_indx = np.where(p_vel_s >= p_vel_val)[0][0].astype(int)\n",
    "    return [c_pos_indx, c_vel_indx, p_ang_indx, p_vel_indx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NODES:  2\n",
      "Number of EPISODES per NODE 2\n"
     ]
    }
   ],
   "source": [
    "T_LR           = 1e-1\n",
    "T_GAMMA        = 0.95\n",
    "T_EPSILON      = 0.98\n",
    "\n",
    "NO_OF_NODES    = 2\n",
    "NO_OF_EPISODES = 2\n",
    "TIMESTEP_LIMIT = 200\n",
    "\n",
    "print(\"Number of NODES: \", NO_OF_NODES)\n",
    "print(\"Number of EPISODES per NODE\", NO_OF_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "HIDDEN_LAYER        = 50\n",
    "BATCH_SIZE          = 32\n",
    "NN_LR               = 1e-3  # learning rate\n",
    "NN_GAMMA            = 0.9   # reward discount\n",
    "TARGET_REPLACE_ITER = 100   # target update frequency\n",
    "TERMINAL_BIAS       = 0.5   # no. of terminal memories in batch\n",
    "MIN_MEMORY_CAP      = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NO_OF_ITERATIONS = 10\n",
    "MAX_NN_ITERATIONS    = 7000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(N_STATES, 50)\n",
    "        nn.init.kaiming_uniform_(self.fc1.weight)   # initialization\n",
    "        self.out = nn.Linear(50, N_ACTIONS)\n",
    "        nn.init.xavier_uniform_(self.out.weight)   # initialization\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        actions_value = self.out(x)\n",
    "        return actions_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDQN(object):\n",
    "    def __init__(self):\n",
    "        self.eval_net, self.target_net = Net(), Net()\n",
    "#         print(\"Neural net\")\n",
    "#         print(self.eval_net)\n",
    "\n",
    "        self.learn_step_counter  = 0 # for target updating\n",
    "        \n",
    "        self.good_memory_counter = 0 # for storing non-terminal memories\n",
    "        self.good_memory         = np.zeros((MIN_MEMORY_CAP ,N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.bad_memory_counter  = 0 # for storing terminal memories\n",
    "        self.bad_memory          = np.zeros((MIN_MEMORY_CAP , N_STATES*2+2))#np.zeros((int(MEMORY_CAPACITY/2), N_STATES * 2 + 2)) # initialize memory\n",
    "        \n",
    "        self.optimizer           = torch.optim.Adam(self.eval_net.parameters(), lr=NN_LR)\n",
    "        self.loss_func           = nn.MSELoss()\n",
    "\n",
    "    def choose_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        if np.random.uniform() < EPSILON:   # greedy\n",
    "            actions_value = self.eval_net.forward(x)\n",
    "            action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "            action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        else:   # random\n",
    "            action = np.random.randint(0, N_ACTIONS)\n",
    "            action = action if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)\n",
    "        return action\n",
    "    \n",
    "    def choose_greedy_action(self, x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        # input only one sample\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        action = torch.max(actions_value, 1)[1].data.numpy()\n",
    "        action = action[0] if ENV_A_SHAPE == 0 else action.reshape(ENV_A_SHAPE)  # return the argmax index\n",
    "        return action\n",
    "\n",
    "    def get_qvals(self,x):\n",
    "        x = torch.unsqueeze(torch.FloatTensor(x), 0)\n",
    "        actions_value = self.eval_net.forward(x)\n",
    "        actions_value = actions_value.data.numpy()\n",
    "        return actions_value\n",
    "\n",
    "    def learn(self):\n",
    "        # target parameter update\n",
    "        if self.learn_step_counter % TARGET_REPLACE_ITER == 0:\n",
    "            self.target_net.load_state_dict(self.eval_net.state_dict())\n",
    "        self.learn_step_counter += 1\n",
    "\n",
    "        # sample batch transitions\n",
    "        good_sample_index_limit = min(MIN_MEMORY_CAP, self.good_memory_counter)\n",
    "        bad_sample_index_limit = min(MIN_MEMORY_CAP, self.bad_memory_counter)\n",
    "\n",
    "        good_sample_index = np.random.choice(int(good_sample_index_limit), int(BATCH_SIZE-int(BATCH_SIZE*TERMINAL_BIAS)))\n",
    "        bad_sample_index  = np.random.choice(int(bad_sample_index_limit),  int(BATCH_SIZE*TERMINAL_BIAS))\n",
    "\n",
    "        b_good_memory = self.good_memory[good_sample_index, :]\n",
    "        b_bad_memory  = self.bad_memory[bad_sample_index, :]\n",
    "        b_memory      = np.vstack((b_good_memory,b_bad_memory))\n",
    "        \n",
    "        b_s  = torch.FloatTensor(b_memory[:, :N_STATES])\n",
    "        b_a  = torch.LongTensor( b_memory[:, N_STATES:N_STATES+1].astype(int))\n",
    "        b_r  = torch.FloatTensor(b_memory[:, N_STATES+1:N_STATES+2])\n",
    "        b_s_ = torch.FloatTensor(b_memory[:, -N_STATES:])\n",
    "\n",
    "        # q_eval w.r.t the action in experience\n",
    "        q_eval   = self.eval_net(b_s).gather(1, b_a)  # shape (batch, 1)\n",
    "        a_eval   = self.eval_net(b_s).max(1)[1].view(BATCH_SIZE, 1) #best action according to eval_net\n",
    "        q_next   = self.target_net(b_s_).detach()     # detach from graph, don't backpropagate\n",
    "        q_target = b_r + NN_GAMMA * q_next.gather(1, a_eval)   # shape (batch, 1)\n",
    "        loss     = self.loss_func(q_eval, q_target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_serial_timesteps   = 0\n",
    "total_parallel_timesteps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn = DDQN()\n",
    "# INITIALIZE MODEL FILE\n",
    "torch.save(dqn.eval_net.state_dict(), MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mp_node_run(node_id):\n",
    "    # SET SEED\n",
    "    ###############################################\n",
    "    my_seed = seed + node_id + iteration\n",
    "    random.seed(my_seed)\n",
    "    torch.manual_seed(my_seed)\n",
    "    np.random.seed(my_seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(my_seed)\n",
    "    my_env = env\n",
    "    my_env.seed(my_seed)\n",
    "    ###############################################\n",
    "\n",
    "    # SET STATE VALUE_LIMITS\n",
    "    ###############################################\n",
    "    C_POS_MAX =  5\n",
    "    C_POS_MIN = -5\n",
    "\n",
    "    C_VEL_MAX =  5\n",
    "    C_VEL_MIN = -5\n",
    "\n",
    "    P_ANG_MAX =  1\n",
    "    P_ANG_MIN = -1\n",
    "\n",
    "    P_VEL_MAX =  5\n",
    "    P_VEL_MIN = -5\n",
    "    ###############################################\n",
    "\n",
    "    # SET GRANULARITY\n",
    "    GRANULARITY = 50\n",
    "\n",
    "    # CREATE STATE TABLE BORDERS\n",
    "    ###############################################\n",
    "    c_pos_s = np.linspace(C_POS_MIN, C_POS_MAX, GRANULARITY)\n",
    "    c_vel_s = np.linspace(C_VEL_MIN, C_VEL_MAX, GRANULARITY)\n",
    "    p_ang_s = np.linspace(P_ANG_MIN, P_ANG_MAX, GRANULARITY)\n",
    "    p_vel_s = np.linspace(P_VEL_MIN, P_VEL_MAX, GRANULARITY)\n",
    "    borders = [c_pos_s, c_vel_s, p_ang_s, p_vel_s]\n",
    "    ###############################################\n",
    "\n",
    "    # CREATE STATE COMBINATIONS\n",
    "    ###############################################\n",
    "\n",
    "    state_combinations = ndim_grid([C_POS_MIN, C_VEL_MIN, P_ANG_MIN, P_VEL_MIN],\n",
    "                                [C_POS_MAX, C_VEL_MAX, P_ANG_MAX, P_VEL_MAX],\n",
    "                                GRANULARITY)\n",
    "    ###############################################\n",
    "\n",
    "    my_dqn = DDQN()\n",
    "    my_dqn.eval_net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "    my_dqn.eval_net.eval()\n",
    "    my_Q_TABLE = my_dqn.get_qvals(state_combinations).reshape(GRANULARITY,GRANULARITY,GRANULARITY,GRANULARITY,-1)\n",
    "\n",
    "    time_rec                = np.zeros(NO_OF_EPISODES)\n",
    "    level_up_flag           = False\n",
    "    PERFECT_RUN_COUNTER     = 10\n",
    "    PERFECT_RUNS_HIGH_SCORE = 10\n",
    "    level_up_metric         = 195\n",
    "\n",
    "    exp_rec      = np.empty(N_STATES * 2 + 2)\n",
    "    my_EPSILON   = T_EPSILON\n",
    "    my_LR        = T_LR\n",
    "\n",
    "    while True:\n",
    "        i_episode = 0\n",
    "        \n",
    "        while i_episode < NO_OF_EPISODES:\n",
    "            ep_exp_rec = np.empty(N_STATES * 2 + 2)\n",
    "            time_steps = 0\n",
    "\n",
    "            s = my_env.reset()\n",
    "            while True:\n",
    "                this_state = tuple(discretize(s, borders))\n",
    "                \n",
    "                time_steps += 1\n",
    "                if np.random.uniform() > my_EPSILON:   # greedy\n",
    "                    a = np.random.randint(0, N_ACTIONS)\n",
    "                else:\n",
    "                    a = my_Q_TABLE[this_state][:].argmax()\n",
    "\n",
    "                 # take action\n",
    "                s_, r, done, info = my_env.step(a)\n",
    "\n",
    "                if done:\n",
    "                    r = -1\n",
    "                    if time_steps >= TIMESTEP_LIMIT:\n",
    "                        r = 1\n",
    "\n",
    "                experience = np.hstack((s,a,r,s_))\n",
    "                exp_rec = np.vstack((exp_rec, experience))\n",
    "\n",
    "                #discretize next_state\n",
    "                next_state = tuple(discretize(s_, borders))\n",
    "\n",
    "                # learn\n",
    "\n",
    "                my_Q_TABLE[this_state][a] = my_Q_TABLE[this_state][a] + my_LR * (r + T_GAMMA * my_Q_TABLE[next_state].max() - \n",
    "                                                                         my_Q_TABLE[this_state][a])\n",
    "                if done:\n",
    "                    time_rec[i_episode] = time_steps\n",
    "                    break\n",
    "                s = s_\n",
    "\n",
    "            i_episode += 1\n",
    "        if i_episode >= NO_OF_EPISODES:\n",
    "            i_episode = 0\n",
    "            break\n",
    "\n",
    "    exp_rec = np.delete(exp_rec, 0, 0)\n",
    "    #     message = \"NODE#\"+str(node_id) +\" MAIN Q:\"+ str(new_Q_TABLE.mean()) +\"\\t\" + \"NODE Q:\" + str(my_Q_TABLE.mean())\n",
    "    #     print(message)\n",
    "    return exp_rec, time_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ITERATION # 0\n",
      "TABULAR EPSILON =  0.98\n",
      "TABULAR LR      =  0.1\n",
      "LARGEST TIMESTEP in ITERATION 0: 10\n",
      "REAL TIME TO GENERATE 40 EXPERIENCES:0:00:03.933965\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "iteration = 0\n",
    "dqn = DDQN()\n",
    "# INITIALIZE MODEL FILE\n",
    "torch.save(dqn.eval_net.state_dict(), MODEL_FILENAME)\n",
    "\n",
    "v_env = gym.make('CartPole-v0')\n",
    "v_env.seed(seed*2)\n",
    "\n",
    "# Create a pool of processes\n",
    "pool = mp.Pool(NO_OF_NODES)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"ITERATION #\", iteration)\n",
    "print(\"TABULAR EPSILON = \", T_EPSILON)\n",
    "print(\"TABULAR LR      = \", T_LR)\n",
    "\n",
    "tic = datetime.now()\n",
    "\n",
    "# MAP GYM ENVIRONMENT TO EACH PROCESS IN THE POOL\n",
    "##################################################################\n",
    "args = range(NO_OF_NODES)\n",
    "result = pool.map(mp_node_run, args)\n",
    "##################################################################\n",
    "\n",
    "# GATHER RESULTS\n",
    "##################################################################\n",
    "node_time_rec = np.array([item[1] for item in result])\n",
    "node_exp = np.array([item[0] for item in result ])\n",
    "all_exp = np.array([item for each_node_exp in node_exp \n",
    "                            for episode_exp in each_node_exp \n",
    "                                for item in episode_exp]).reshape(-1,10)\n",
    "total_parallel_timesteps += node_time_rec.max()\n",
    "total_serial_timesteps   += node_time_rec.sum()\n",
    "EXP_GEN = node_time_rec.sum().astype(int)\n",
    "\n",
    "print(\"LARGEST TIMESTEP in ITERATION {:d}: {:d}\".format(iteration, node_time_rec.max().astype(int)))\n",
    "print(\"REAL TIME TO GENERATE {:d} EXPERIENCES:{}\".format(EXP_GEN, (datetime.now()-tic)))\n",
    "##################################################################\n",
    "\n",
    "# PLOT EXPERIENCES\n",
    "##################################################################\n",
    "node_avg_time = node_time_rec.mean(axis=1)\n",
    "node_std_time = node_time_rec.std(axis=1)\n",
    "node_max_time = node_time_rec.max(axis=1)\n",
    "node_min_time = node_time_rec.min(axis=1)\n",
    "\n",
    "fig = plt.figure(figsize = (15,3))\n",
    "ax2 = fig.add_subplot(1, 1, 1)\n",
    "ax2.set_title(\"Q-table Performance\")\n",
    "ax2.bar(range(NO_OF_NODES) , node_max_time, alpha = 0.1, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_avg_time, alpha = 0.5, color = 'g', edgecolor = 'black', capsize=7 )\n",
    "ax2.bar(range(NO_OF_NODES) , node_min_time, alpha = 0.4, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "\n",
    "ax2.plot(np.ones_like(node_avg_time)*200, 'g--')\n",
    "ax2.set_ylabel('Mean Node Lifetime',color = 'g')\n",
    "ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "fig.tight_layout()\n",
    "ax2.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration = 0\n",
    "# dqn = DDQN()\n",
    "# # INITIALIZE MODEL FILE\n",
    "# torch.save(dqn.eval_net.state_dict(), MODEL_FILENAME)\n",
    "\n",
    "# v_env = gym.make('CartPole-v0')\n",
    "# v_env.seed(seed*2)\n",
    "\n",
    "# # Create a pool of processes\n",
    "# pool = mp.Pool(NO_OF_NODES)\n",
    "\n",
    "# while iteration < MAX_NO_OF_ITERATIONS:\n",
    "#     print(\"\\n\")\n",
    "#     print(\"ITERATION #\", iteration)\n",
    "#     print(\"TABULAR EPSILON = \", T_EPSILON)\n",
    "#     print(\"TABULAR LR      = \", T_LR)\n",
    "\n",
    "#     tic = datetime.now()\n",
    "\n",
    "#     # MAP GYM ENVIRONMENT TO EACH PROCESS IN THE POOL\n",
    "#     ##################################################################\n",
    "#     args = range(NO_OF_NODES)\n",
    "#     result = pool.map(mp_node_run, args)\n",
    "#     ##################################################################\n",
    "    \n",
    "#     # GATHER RESULTS\n",
    "#     ##################################################################\n",
    "#     node_time_rec = np.array([item[1] for item in result])\n",
    "#     node_exp = np.array([item[0] for item in result ])\n",
    "#     all_exp = np.array([item for each_node_exp in node_exp \n",
    "#                                 for episode_exp in each_node_exp \n",
    "#                                     for item in episode_exp]).reshape(-1,10)\n",
    "#     total_parallel_timesteps += node_time_rec.max()\n",
    "#     total_serial_timesteps   += node_time_rec.sum()\n",
    "#     EXP_GEN = node_time_rec.sum().astype(int)\n",
    "\n",
    "#     print(\"LARGEST TIMESTEP in ITERATION {:d}: {:d}\".format(iteration, node_time_rec.max().astype(int)))\n",
    "#     print(\"REAL TIME TO GENERATE {:d} EXPERIENCES:{}\".format(EXP_GEN, (datetime.now()-tic)))\n",
    "#     ##################################################################\n",
    "    \n",
    "#     # PLOT EXPERIENCES\n",
    "#     ##################################################################\n",
    "#     node_avg_time = node_time_rec.mean(axis=1)\n",
    "#     node_std_time = node_time_rec.std(axis=1)\n",
    "#     node_max_time = node_time_rec.max(axis=1)\n",
    "#     node_min_time = node_time_rec.min(axis=1)\n",
    "\n",
    "#     fig = plt.figure(figsize = (15,3))\n",
    "#     ax2 = fig.add_subplot(1, 1, 1)\n",
    "#     ax2.set_title(\"Q-table Performance\")\n",
    "#     ax2.bar(range(NO_OF_NODES) , node_max_time, alpha = 0.1, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "#     ax2.bar(range(NO_OF_NODES) , node_avg_time, alpha = 0.5, color = 'g', edgecolor = 'black', capsize=7 )\n",
    "#     ax2.bar(range(NO_OF_NODES) , node_min_time, alpha = 0.4, color = 'r', edgecolor = 'black', capsize=7 )\n",
    "\n",
    "#     ax2.plot(np.ones_like(node_avg_time)*200, 'g--')\n",
    "#     ax2.set_ylabel('Mean Node Lifetime',color = 'g')\n",
    "#     ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "#     fig.tight_layout()\n",
    "#     ax2.grid()\n",
    "#     plt.show()\n",
    "#     ##################################################################\n",
    "\n",
    "#     if node_min_time.min() > 195:\n",
    "#         print(\"Problem SOLVED in iteration#\", iteration)\n",
    "#         break\n",
    "\n",
    "#     # SEGREGATE AND STORE EXPERIENCES\n",
    "#     ##################################################################\n",
    "#     good_mem = all_exp[all_exp[:,5] == 1]\n",
    "#     bad_mem  = all_exp[all_exp[:,5]  < 1]\n",
    "\n",
    "\n",
    "#     dqn.good_memory = np.insert(dqn.good_memory, 0, good_mem , 0)\n",
    "#     dqn.good_memory_counter += good_mem.shape[0]\n",
    "\n",
    "#     dqn.bad_memory  = np.insert(dqn.bad_memory, 0, bad_mem , 0)\n",
    "#     dqn.bad_memory_counter += bad_mem.shape[0]\n",
    "\n",
    "#     dqn.good_memory = dqn.good_memory[:MIN_MEMORY_CAP,:]\n",
    "#     dqn.bad_memory = dqn.bad_memory[:MIN_MEMORY_CAP,:]\n",
    "\n",
    "#     NN_ITERATIONS = MAX_NN_ITERATIONS\n",
    "\n",
    "#     print(\"GOOD MEMORY COUNTER: \", min(MIN_MEMORY_CAP, dqn.good_memory_counter))\n",
    "#     print(\"BAD MEMORY COUNTER: \", min(MIN_MEMORY_CAP, dqn.bad_memory_counter))\n",
    "#     ##################################################################\n",
    "\n",
    "#     # LEARN\n",
    "#     ##################################################################\n",
    "#     print(\"Training Neural Network for\", NN_ITERATIONS, \"iterations\", \"@ LR = \", NN_LR)\n",
    "#     print(int(BATCH_SIZE*TERMINAL_BIAS),\"TERMINAL EXPERIENCES IN A BATCH SIZE OF\",BATCH_SIZE)\n",
    "#     tic=datetime.now()\n",
    "#     nn_level_up_metric = 0\n",
    "#     for nn_iter in range(NN_ITERATIONS):\n",
    "#         dqn.learn()\n",
    "#         #validate by running for TIMESTEP_LIMIT iterations\n",
    "#         if(nn_iter%int(NN_ITERATIONS/5) == int(NN_ITERATIONS/5)-1):\n",
    "#             print(\"Validating... \",end=\"\")\n",
    "#             time_rec = []\n",
    "#             for i_episode in range(TIMESTEP_LIMIT):\n",
    "#                 time_step = 0\n",
    "#                 s = v_env.reset()\n",
    "#                 while True:\n",
    "#                     time_step += 1 \n",
    "#                     a = dqn.choose_greedy_action(s)\n",
    "#                     s_, r, done, info = v_env.step(a)\n",
    "#                     if done:\n",
    "#                         break\n",
    "#                     s = s_\n",
    "#                 time_rec = np.append(time_rec, time_step)\n",
    "#             mean_time = time_rec.mean()\n",
    "#             print(\"MEAN TIME: \", mean_time)\n",
    "#             if mean_time >= nn_level_up_metric:\n",
    "#                 nn_level_up_metric = mean_time\n",
    "#                 torch.save(dqn.eval_net.state_dict(), MODEL_FILENAME)\n",
    "\n",
    "#     print(\"TRAINING TIME:{}\".format(datetime.now()-tic))\n",
    "#     ##################################################################\n",
    "\n",
    "#     # CHECK PERFORMANCE OF THE BEST MODEL\n",
    "#     ##################################################################\n",
    "#     best_dqn = DDQN()\n",
    "#     best_dqn.eval_net.load_state_dict(torch.load(MODEL_FILENAME))\n",
    "#     best_dqn.eval_net.eval()\n",
    "\n",
    "#     #test NN policy using BEST MODEL\n",
    "#     time_rec = []\n",
    "#     for i_episode in range(TIMESTEP_LIMIT):\n",
    "#         time_step = 0\n",
    "#         s = env.reset()\n",
    "#         while True:\n",
    "#     #         env.render()\n",
    "#             time_step += 1 \n",
    "#             a = best_dqn.choose_greedy_action(s)\n",
    "#             s_, r, done, info = env.step(a)\n",
    "#             if done:\n",
    "#                 break\n",
    "#             s = s_\n",
    "#         time_rec = np.append(time_rec, time_step)\n",
    "\n",
    "#     fig = plt.figure(figsize = (15,3))\n",
    "#     ax2 = fig.add_subplot(1, 1, 1)\n",
    "#     data = time_rec\n",
    "#     ax2.plot(data, color = 'm')\n",
    "#     ax2.plot(np.ones_like(data)*200, 'm--')\n",
    "#     ax2.set_title('Neural Network Performance using BEST MODEL ')\n",
    "#     ax2.set_ylabel('Time Steps',color = 'm')\n",
    "#     ax2.set_ylim(0,TIMESTEP_LIMIT+10)\n",
    "#     fig.tight_layout()\n",
    "#     ax2.grid()\n",
    "#     plt.show()\n",
    "#     ##################################################################\n",
    "#     iteration += 1\n",
    "# pool.close()\n",
    "# pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total Parallel Timesteps : \", total_parallel_timesteps)\n",
    "print(\"Total Serial Timesteps   : \", total_serial_timesteps)\n",
    "print(\"Speed-up                 :  {:6.2f}\".format(total_serial_timesteps/total_parallel_timesteps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
